Student: s1115104
Date: 24-10-2015

Output directory: /user/s1115104/data/output/exc-cw1/

###########################################################
# Task 1
###########################################################

Mapping to lowercase requires no reducers.

Task 1 code begin
Run:
#!/usr/bin/bash
hdfs dfs -rm -r /user/s1115104/data/output/exc-cw2/s1115104_task_1_small.out

hadoop jar /opt/hadoop/hadoop-2.7.1/share/hadoop/tools/lib/hadoop-streaming-2.7.1.jar \
 -D mapred.reduce.tasks=5 \
 -D mapreduce.job.output.key.comparator.class=org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedComparator \
 -D stream.num.map.output.key.fields=1 \
 -D num.key.fields.for.partition=1 \
 -D mapreduce.partition.keypartitioner.options=-k1,1 \
 -D mapreduce.partition.keycomparator.options="-k1,1 -k2,2" \
 -D mapreduce.map.output.key.field.separator=" " \
 -input /data/assignments/ex2/task1/small/ \
 -output /user/s1115104/data/output/exc-cw2/s1115104_task_1_small.out \
 -mapper mapper.py \
 -file mapper.py \
 -combiner combiner.py \
 -file combiner.py \
 -reducer reducer.py \
 -file reducer.py \
 -jobconf mapred.job.name="Inverted Index S" \
 -partitioner org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner \



hdfs dfs -cat /user/s1115104/data/output/exc-cw2/s1115104_task_6_small.out/part-00001 | head -n 100
########################################################
#!/usr/bin/python
import os
import sys
import string
from collections import Counter

filename = os.environ['mapreduce_map_input_file'].split('/')[-1]

trans = string.maketrans('', '')

for line in sys.stdin:
    line = line.strip().lower()
    # Remove punctuation
    line = line.translate(trans, string.punctuation)
    words = line.split()
    if words:
        counter = Counter(words)

        for (word, count) in counter.iteritems():
            print("{0} {1} {2}".format(word, filename, count))

########################################################
#!/usr/bin/python
import os
import sys
from collections import Counter

last_word = None
last_filename = None
accumulator = 0

# Input is received sorted by word and by filename
for line in sys.stdin:
    line = line.strip()

    word, filename, count = line.split(' ', 2)

    if last_word is not None and word != last_word:
        print("{0} {1} {2}".format(last_word, last_filename, accumulator))
        accumulator = 0

    last_word = word
    last_filename = filename
    accumulator += int(count)


if last_word is not None:
    print("{0} {1} {2}".format(last_word, last_filename, accumulator))
########################################################
#!/usr/bin/python
import sys

word_counter = 0
last_word = None
word_documents = []


def write(keyword, total, documents):
    docs = ", ".join(["(%s, %d)" % (doc, count) for doc, count in documents])
    docs = "{%s}" % docs
    print("{0} : {1} : {2}".format(keyword, total, docs))

# Input is sorted primarily by word, secondarily by
# document name. Single pass is required without doing any
# sorting.
#
# Expected input:
#   also        d1.txt  13
#   also        d3.txt  8
#   also        d4.txt  3
#   altered     d5.txt  1
#   althorp     d5.txt  2
for line in sys.stdin:
    word, doc, count = line.split(' ', 2)

    if last_word is not None and last_word != word:
        # Cleanup after last block
        write(last_word, word_counter, word_documents)
        # Start new block
        word_documents = []
        word_counter = 0

    count = int(count)

    last_word = word
    word_counter += count
    word_documents.append((doc, count))

if last_word is not None:
    write(last_word, word_counter, word_documents)



Task 1 code end

Task 1 results begin
