#!/bin/bash

export EXC2_4_3_BASE=/user/s1115104/data/output/exc-cw2/s1115104_task_4_3.out
export EXC2_4_3_INPUT=/data/assignments/ex2/task3/stackLarge.txt
export EXC2_4_3_JOIN=/user/s1115104/data/output/exc-cw2/s1115104_task_4_3.out/join
export EXC2_4_3_OUTPUT=/user/s1115104/data/output/exc-cw2/s1115104_task_4_3.out/aggregate

hdfs dfs -mkdir $EXC2_4_3_BASE

hadoop jar /opt/hadoop/hadoop-2.7.1/share/hadoop/tools/lib/hadoop-streaming-2.7.1.jar \
    -D mapred.job.name="WANTED: Best StackOverflow User - Join. EXC 2 4-4 L" \
    -D mapred.reduce.tasks=16 \
    -D mapreduce.job.output.key.comparator.class=org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedComparator \
    -D stream.num.map.output.key.fields=1 \
    -D num.key.fields.for.partition=1 \
    -D mapreduce.partition.keypartitioner.options=-k1,1 \
    -D mapreduce.partition.keycomparator.options="-k1,1 -k2,2r" \
    -D mapreduce.map.output.key.field.separator=" " \
    -input $EXC2_4_3_INPUT \
    -output $EXC2_4_3_JOIN \
    -mapper join-mapper.py \
    -reducer join-reducer.py \
    -file join-mapper.py \
    -file join-reducer.py \
    -partitioner org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner

# Verify previous step suceeded
if hdfs dfs -test -e $EXC2_4_3_JOIN/_SUCCESS ; then

    hadoop jar /opt/hadoop/hadoop-2.7.1/share/hadoop/tools/lib/hadoop-streaming-2.7.1.jar \
        -D mapred.job.name="WANTED: Best StackOverflow User - Aggregate. EXC 2 4-4 S" \
        -D mapred.reduce.tasks=1 \
        -input $EXC2_4_3_JOIN \
        -output $EXC2_4_3_OUTPUT \
        -mapper cat \
        -combiner aggregate-combiner.py \
        -reducer aggregate-reducer.py \
        -file aggregate-combiner.py \
        -file aggregate-reducer.py

    hdfs dfs -cat $EXC2_4_3_OUTPUT/part-* | head -n 10 > results.txt
fi

