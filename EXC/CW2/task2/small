#!/usr/bin/bash
export EXC2_2_INPUT=/data/assignments/ex2/task1/small/
export EXC2_2_OUTPUT=/user/s1115104/data/output/exc-cw2/s1115104_task_2_small.out

# Clean up last run
hdfs dfs -rm -r $EXC2_2_OUTPUT

# Fetch terms to look for
hdfs dfs -get /data/assignments/ex2/terms.txt ./terms.txt

hadoop jar /opt/hadoop/hadoop-2.7.1/share/hadoop/tools/lib/hadoop-streaming-2.7.1.jar \
 -D mapred.reduce.tasks=1 \
 -input $EXC2_2_INPUT \
 -output $EXC2_2_OUTPUT \
 -mapper "mapper.py `hdfs dfs -ls $EXC2_2_INPUT | grep -v "_SUCCESS\|Found" | wc -l`"\
 -file mapper.py \
 -jobconf mapred.job.name="TF-IDF S" \
 -file terms.txt
 # -reducer cat \
# -combiner combiner.py \
#  -file combiner.py \

#  -file reducer.py \

hdfs dfs -cat $EXC2_2_OUTPUT/part-* | head -n 100