#!/usr/bin/bash

hadoop jar /opt/hadoop/hadoop-2.7.1/share/hadoop/tools/lib/hadoop-streaming-2.7.1.jar \
 -D mapreduce.job.output.key.comparator.class=org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedComparator \
 -D stream.num.map.output.key.fields=2 \
 -D num.key.fields.for.partition=1 \
 -D mapreduce.partition.keycomparator.options="-k1n -k2r" \
 -input /data/assignments/ex1/uniSmall.txt \
 -output /user/$USER/data/output/task8-small \
 -mapper mapper.py \
 -file mapper.py \
 -reducer reducer.py \
 -file reducer.py \
 -combiner combiner.py \
 -file combiner.py \
 -partitioner org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner \
 -jobconf mapred.map.tasks=32 \
 -jobconf mapred.job.reduces=32 \
 -jobconf mapred.job.name="Students Join Small `echo $USER`"

hdfs dfs -ls /user/$USER/data/output/task8-small

echo "Expected WC: `hdfs dfs -cat /data/assignments/samples/task_8.out/part-00000 | wc -l`"
echo "Produced WC: `hdfs dfs -cat /user/$USER/data/output/task8-small/part-* | wc -l`"

